Training started at: 2019-04-25 01:57:51.833400
#2 CUDA device(s) available
--------------------
Training Stats:
#Classes: 2 | #Image Size: 1024 | #Batch Size: 4 | #Epochs: 100 | Learning Rate: 0.0005
Saving model in: /scratch/bva212/dl4medProject/Inception_v2_2_Classes/
--------------------
Using model Inception Net v2 on 2 classes
--------------------

Training Start
--------------------

Epoch 1/100
----------
/home/bva212/dl4medProject/helpers/dataloader.py:40: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  self.data_frame['label'][self.data_frame['label'] == 2] = 0
/home/bva212/dl4medProject/helpers/dataloader.py:41: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  self.data_frame['label'][self.data_frame['label'] == 3] = 1
train Loss: 0.6638 Acc: 0.5945
val Loss: 0.7634 Acc: 0.6372

Epoch 4/100
----------
train Loss: 0.6185 Acc: 0.6576
val Loss: 0.7755 Acc: 0.6372

Epoch 7/100
----------
train Loss: 0.5584 Acc: 0.6988
val Loss: 0.6707 Acc: 0.6357

Epoch 10/100
----------
train Loss: 0.5260 Acc: 0.7331
val Loss: 0.6532 Acc: 0.6496

Epoch 13/100
----------
train Loss: 0.4937 Acc: 0.7493
val Loss: 0.7517 Acc: 0.6481

Epoch 16/100
----------
train Loss: 0.4601 Acc: 0.7790
val Loss: 0.6997 Acc: 0.6574

Epoch 19/100
----------
train Loss: 0.4594 Acc: 0.7748
val Loss: 0.7129 Acc: 0.6698

Epoch 22/100
----------
train Loss: 0.4601 Acc: 0.7808
val Loss: 0.7276 Acc: 0.6651

Epoch 25/100
----------
train Loss: 0.4490 Acc: 0.7799
val Loss: 0.6775 Acc: 0.6651

Epoch 28/100
----------
train Loss: 0.4506 Acc: 0.8003
val Loss: 0.7079 Acc: 0.6744

Epoch 31/100
----------
train Loss: 0.4537 Acc: 0.7878
val Loss: 0.6960 Acc: 0.6698

Epoch 34/100
----------
train Loss: 0.4607 Acc: 0.7868
val Loss: 0.6555 Acc: 0.6744

Epoch 37/100
----------
train Loss: 0.4594 Acc: 0.7841
val Loss: 0.7026 Acc: 0.6543

Epoch 40/100
----------
train Loss: 0.4580 Acc: 0.7836
val Loss: 0.7001 Acc: 0.6589

Epoch 43/100
----------
train Loss: 0.4599 Acc: 0.7794
val Loss: 0.6989 Acc: 0.6667

Epoch 46/100
----------
train Loss: 0.4482 Acc: 0.7808
val Loss: 0.7474 Acc: 0.6496

Epoch 49/100
----------
train Loss: 0.4619 Acc: 0.7794
val Loss: 0.7264 Acc: 0.6605

Epoch 52/100
----------
train Loss: 0.4544 Acc: 0.7817
val Loss: 0.7318 Acc: 0.6667

Epoch 55/100
----------
train Loss: 0.4552 Acc: 0.7831
val Loss: 0.6734 Acc: 0.6775

Epoch 58/100
----------
train Loss: 0.4553 Acc: 0.7813
val Loss: 0.7220 Acc: 0.6574

Epoch 61/100
----------
train Loss: 0.4570 Acc: 0.7841
val Loss: 0.7569 Acc: 0.6605

Epoch 64/100
----------
train Loss: 0.4534 Acc: 0.7915
val Loss: 0.7518 Acc: 0.6434

Epoch 67/100
----------
train Loss: 0.4521 Acc: 0.7892
val Loss: 0.7704 Acc: 0.6574

Epoch 70/100
----------
train Loss: 0.4618 Acc: 0.7799
val Loss: 0.7404 Acc: 0.6636

Epoch 73/100
----------
train Loss: 0.4587 Acc: 0.7753
val Loss: 0.6947 Acc: 0.6698

Epoch 76/100
----------
train Loss: 0.4523 Acc: 0.7845
val Loss: 0.7041 Acc: 0.6682

Epoch 79/100
----------
train Loss: 0.4614 Acc: 0.7720
val Loss: 0.7194 Acc: 0.6651

Epoch 82/100
----------
train Loss: 0.4517 Acc: 0.7882
val Loss: 0.7110 Acc: 0.6605

Epoch 85/100
----------
train Loss: 0.4518 Acc: 0.7808
val Loss: 0.7646 Acc: 0.6837

Epoch 88/100
----------
train Loss: 0.4597 Acc: 0.7873
val Loss: 0.7948 Acc: 0.6605

Epoch 91/100
----------
train Loss: 0.4550 Acc: 0.7882
val Loss: 0.6982 Acc: 0.6775

Epoch 94/100
----------
train Loss: 0.4596 Acc: 0.7854
val Loss: 0.7075 Acc: 0.6605

Epoch 97/100
----------
train Loss: 0.4627 Acc: 0.7799
val Loss: 0.6407 Acc: 0.6791

Epoch 100/100
----------
train Loss: 0.4557 Acc: 0.7878
val Loss: 0.6933 Acc: 0.6605

Training time: 980minutes 0.724541187286377s
Best val Acc: 0.683721

Training Completed

Validation Start
--------------------



Validation End

--------------------THE END------------------
